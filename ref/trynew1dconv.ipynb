{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(576, 1, 1, stride=1, padding=0) #输入为(batch,dim,length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pad_size = 36000 - x.size(1)\n",
    "        x = F.pad(x, (0, 0, 0, pad_size))\n",
    "        print(x.size())\n",
    "\n",
    "        x = x.view(x.size(0), 576, -1)  # adjust to match the input shape, 1,576,33564\n",
    "        print(x.size())\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        print(x.size())\n",
    "        x = self.conv2(x)\n",
    "        print(x.size())\n",
    "        x = self.conv3(x)\n",
    "        print(x.size())\n",
    "        x = self.conv4(x)\n",
    "        print(x.size())\n",
    "        x = self.conv5(x)\n",
    "        print(x.size())\n",
    "        x = self.conv6(x)\n",
    "        print(x.size())\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, else use CPU\n",
    "model = Decoder().to(device)  # Move model to the device\n",
    "\n",
    "encoded = torch.load('quantized33564.pt') #input size is torch.size([1,33564,576])\n",
    "# encoded1 = encoded[0]\n",
    "\n",
    "decoded = model(encoded).to(device)\n",
    "# print(decoded.shape)  # should be [1, 1, 361, 720], but not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:1,stride:1,output:torch.Size([1, 1, 22500])\n",
      "input:([1,576,32400]),kernal:1,stride:2,output:torch.Size([1, 1, 11250])\n",
      "input:([1,576,32400]),kernal:1,stride:3,output:torch.Size([1, 1, 7500])\n",
      "input:([1,576,32400]),kernal:1,stride:4,output:torch.Size([1, 1, 5625])\n",
      "input:([1,576,32400]),kernal:1,stride:5,output:torch.Size([1, 1, 4500])\n",
      "input:([1,576,32400]),kernal:1,stride:6,output:torch.Size([1, 1, 3750])\n",
      "input:([1,576,32400]),kernal:1,stride:7,output:torch.Size([1, 1, 3215])\n",
      "input:([1,576,32400]),kernal:1,stride:8,output:torch.Size([1, 1, 2813])\n",
      "input:([1,576,32400]),kernal:1,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:1,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:2,stride:1,output:torch.Size([1, 1, 22499])\n",
      "input:([1,576,32400]),kernal:2,stride:2,output:torch.Size([1, 1, 11250])\n",
      "input:([1,576,32400]),kernal:2,stride:3,output:torch.Size([1, 1, 7500])\n",
      "input:([1,576,32400]),kernal:2,stride:4,output:torch.Size([1, 1, 5625])\n",
      "input:([1,576,32400]),kernal:2,stride:5,output:torch.Size([1, 1, 4500])\n",
      "input:([1,576,32400]),kernal:2,stride:6,output:torch.Size([1, 1, 3750])\n",
      "input:([1,576,32400]),kernal:2,stride:7,output:torch.Size([1, 1, 3215])\n",
      "input:([1,576,32400]),kernal:2,stride:8,output:torch.Size([1, 1, 2813])\n",
      "input:([1,576,32400]),kernal:2,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:2,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:3,stride:1,output:torch.Size([1, 1, 22498])\n",
      "input:([1,576,32400]),kernal:3,stride:2,output:torch.Size([1, 1, 11249])\n",
      "input:([1,576,32400]),kernal:3,stride:3,output:torch.Size([1, 1, 7500])\n",
      "input:([1,576,32400]),kernal:3,stride:4,output:torch.Size([1, 1, 5625])\n",
      "input:([1,576,32400]),kernal:3,stride:5,output:torch.Size([1, 1, 4500])\n",
      "input:([1,576,32400]),kernal:3,stride:6,output:torch.Size([1, 1, 3750])\n",
      "input:([1,576,32400]),kernal:3,stride:7,output:torch.Size([1, 1, 3214])\n",
      "input:([1,576,32400]),kernal:3,stride:8,output:torch.Size([1, 1, 2813])\n",
      "input:([1,576,32400]),kernal:3,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:3,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:4,stride:1,output:torch.Size([1, 1, 22497])\n",
      "input:([1,576,32400]),kernal:4,stride:2,output:torch.Size([1, 1, 11249])\n",
      "input:([1,576,32400]),kernal:4,stride:3,output:torch.Size([1, 1, 7499])\n",
      "input:([1,576,32400]),kernal:4,stride:4,output:torch.Size([1, 1, 5625])\n",
      "input:([1,576,32400]),kernal:4,stride:5,output:torch.Size([1, 1, 4500])\n",
      "input:([1,576,32400]),kernal:4,stride:6,output:torch.Size([1, 1, 3750])\n",
      "input:([1,576,32400]),kernal:4,stride:7,output:torch.Size([1, 1, 3214])\n",
      "input:([1,576,32400]),kernal:4,stride:8,output:torch.Size([1, 1, 2813])\n",
      "input:([1,576,32400]),kernal:4,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:4,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:5,stride:1,output:torch.Size([1, 1, 22496])\n",
      "input:([1,576,32400]),kernal:5,stride:2,output:torch.Size([1, 1, 11248])\n",
      "input:([1,576,32400]),kernal:5,stride:3,output:torch.Size([1, 1, 7499])\n",
      "input:([1,576,32400]),kernal:5,stride:4,output:torch.Size([1, 1, 5624])\n",
      "input:([1,576,32400]),kernal:5,stride:5,output:torch.Size([1, 1, 4500])\n",
      "input:([1,576,32400]),kernal:5,stride:6,output:torch.Size([1, 1, 3750])\n",
      "input:([1,576,32400]),kernal:5,stride:7,output:torch.Size([1, 1, 3214])\n",
      "input:([1,576,32400]),kernal:5,stride:8,output:torch.Size([1, 1, 2812])\n",
      "input:([1,576,32400]),kernal:5,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:5,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:6,stride:1,output:torch.Size([1, 1, 22495])\n",
      "input:([1,576,32400]),kernal:6,stride:2,output:torch.Size([1, 1, 11248])\n",
      "input:([1,576,32400]),kernal:6,stride:3,output:torch.Size([1, 1, 7499])\n",
      "input:([1,576,32400]),kernal:6,stride:4,output:torch.Size([1, 1, 5624])\n",
      "input:([1,576,32400]),kernal:6,stride:5,output:torch.Size([1, 1, 4499])\n",
      "input:([1,576,32400]),kernal:6,stride:6,output:torch.Size([1, 1, 3750])\n",
      "input:([1,576,32400]),kernal:6,stride:7,output:torch.Size([1, 1, 3214])\n",
      "input:([1,576,32400]),kernal:6,stride:8,output:torch.Size([1, 1, 2812])\n",
      "input:([1,576,32400]),kernal:6,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:6,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:7,stride:1,output:torch.Size([1, 1, 22494])\n",
      "input:([1,576,32400]),kernal:7,stride:2,output:torch.Size([1, 1, 11247])\n",
      "input:([1,576,32400]),kernal:7,stride:3,output:torch.Size([1, 1, 7498])\n",
      "input:([1,576,32400]),kernal:7,stride:4,output:torch.Size([1, 1, 5624])\n",
      "input:([1,576,32400]),kernal:7,stride:5,output:torch.Size([1, 1, 4499])\n",
      "input:([1,576,32400]),kernal:7,stride:6,output:torch.Size([1, 1, 3749])\n",
      "input:([1,576,32400]),kernal:7,stride:7,output:torch.Size([1, 1, 3214])\n",
      "input:([1,576,32400]),kernal:7,stride:8,output:torch.Size([1, 1, 2812])\n",
      "input:([1,576,32400]),kernal:7,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:7,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:8,stride:1,output:torch.Size([1, 1, 22493])\n",
      "input:([1,576,32400]),kernal:8,stride:2,output:torch.Size([1, 1, 11247])\n",
      "input:([1,576,32400]),kernal:8,stride:3,output:torch.Size([1, 1, 7498])\n",
      "input:([1,576,32400]),kernal:8,stride:4,output:torch.Size([1, 1, 5624])\n",
      "input:([1,576,32400]),kernal:8,stride:5,output:torch.Size([1, 1, 4499])\n",
      "input:([1,576,32400]),kernal:8,stride:6,output:torch.Size([1, 1, 3749])\n",
      "input:([1,576,32400]),kernal:8,stride:7,output:torch.Size([1, 1, 3214])\n",
      "input:([1,576,32400]),kernal:8,stride:8,output:torch.Size([1, 1, 2812])\n",
      "input:([1,576,32400]),kernal:8,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:8,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:9,stride:1,output:torch.Size([1, 1, 22492])\n",
      "input:([1,576,32400]),kernal:9,stride:2,output:torch.Size([1, 1, 11246])\n",
      "input:([1,576,32400]),kernal:9,stride:3,output:torch.Size([1, 1, 7498])\n",
      "input:([1,576,32400]),kernal:9,stride:4,output:torch.Size([1, 1, 5623])\n",
      "input:([1,576,32400]),kernal:9,stride:5,output:torch.Size([1, 1, 4499])\n",
      "input:([1,576,32400]),kernal:9,stride:6,output:torch.Size([1, 1, 3749])\n",
      "input:([1,576,32400]),kernal:9,stride:7,output:torch.Size([1, 1, 3214])\n",
      "input:([1,576,32400]),kernal:9,stride:8,output:torch.Size([1, 1, 2812])\n",
      "input:([1,576,32400]),kernal:9,stride:9,output:torch.Size([1, 1, 2500])\n",
      "input:([1,576,32400]),kernal:9,stride:10,output:torch.Size([1, 1, 2250])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:10,stride:1,output:torch.Size([1, 1, 22491])\n",
      "input:([1,576,32400]),kernal:10,stride:2,output:torch.Size([1, 1, 11246])\n",
      "input:([1,576,32400]),kernal:10,stride:3,output:torch.Size([1, 1, 7497])\n",
      "input:([1,576,32400]),kernal:10,stride:4,output:torch.Size([1, 1, 5623])\n",
      "input:([1,576,32400]),kernal:10,stride:5,output:torch.Size([1, 1, 4499])\n",
      "input:([1,576,32400]),kernal:10,stride:6,output:torch.Size([1, 1, 3749])\n",
      "input:([1,576,32400]),kernal:10,stride:7,output:torch.Size([1, 1, 3213])\n",
      "input:([1,576,32400]),kernal:10,stride:8,output:torch.Size([1, 1, 2812])\n",
      "input:([1,576,32400]),kernal:10,stride:9,output:torch.Size([1, 1, 2499])\n",
      "input:([1,576,32400]),kernal:10,stride:10,output:torch.Size([1, 1, 2250])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.randn(1,576,22500) #channel 长 宽\n",
    "for ker in range(1,11):\n",
    "    print('\\n')\n",
    "    for strr in range(1,11):\n",
    "        upconv1 = nn.Conv1d(576, 1, kernel_size=ker, stride=strr, padding=0) #维度任人设置 应该是用几个核去卷，所以不涉及几何尺寸问题；ker越大 输出图越大+1；str越大 输出图越大\n",
    "        x = upconv1(x)\n",
    "        print(f'input:([1,576,32400]),kernal:{ker},stride:{strr},output:{x.shape}')  # 想要输出: torch.Size([1, 361, 720])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:1,stride:1,output:torch.Size([1, 1, 22500])\n",
      "input:([1,576,32400]),kernal:1,stride:2,output:torch.Size([1, 1, 11250])\n",
      "input:([1,576,32400]),kernal:1,stride:3,output:torch.Size([1, 1, 7500])\n",
      "input:([1,576,32400]),kernal:1,stride:4,output:torch.Size([1, 1, 5625])\n",
      "input:([1,576,32400]),kernal:1,stride:5,output:torch.Size([1, 1, 4500])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:2,stride:1,output:torch.Size([1, 1, 22499])\n",
      "input:([1,576,32400]),kernal:2,stride:2,output:torch.Size([1, 1, 11250])\n",
      "input:([1,576,32400]),kernal:2,stride:3,output:torch.Size([1, 1, 7500])\n",
      "input:([1,576,32400]),kernal:2,stride:4,output:torch.Size([1, 1, 5625])\n",
      "input:([1,576,32400]),kernal:2,stride:5,output:torch.Size([1, 1, 4500])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:3,stride:1,output:torch.Size([1, 1, 22498])\n",
      "input:([1,576,32400]),kernal:3,stride:2,output:torch.Size([1, 1, 11249])\n",
      "input:([1,576,32400]),kernal:3,stride:3,output:torch.Size([1, 1, 7500])\n",
      "input:([1,576,32400]),kernal:3,stride:4,output:torch.Size([1, 1, 5625])\n",
      "input:([1,576,32400]),kernal:3,stride:5,output:torch.Size([1, 1, 4500])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:4,stride:1,output:torch.Size([1, 1, 22497])\n",
      "input:([1,576,32400]),kernal:4,stride:2,output:torch.Size([1, 1, 11249])\n",
      "input:([1,576,32400]),kernal:4,stride:3,output:torch.Size([1, 1, 7499])\n",
      "input:([1,576,32400]),kernal:4,stride:4,output:torch.Size([1, 1, 5625])\n",
      "input:([1,576,32400]),kernal:4,stride:5,output:torch.Size([1, 1, 4500])\n",
      "\n",
      "\n",
      "input:([1,576,32400]),kernal:5,stride:1,output:torch.Size([1, 1, 22496])\n",
      "input:([1,576,32400]),kernal:5,stride:2,output:torch.Size([1, 1, 11248])\n",
      "input:([1,576,32400]),kernal:5,stride:3,output:torch.Size([1, 1, 7499])\n",
      "input:([1,576,32400]),kernal:5,stride:4,output:torch.Size([1, 1, 5624])\n",
      "input:([1,576,32400]),kernal:5,stride:5,output:torch.Size([1, 1, 4500])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.randn(1,576,22500) #channel 长 宽\n",
    "for ker in range(1,6):\n",
    "    print('\\n')\n",
    "    for strr in range(1,6):\n",
    "        upconv1 = nn.Conv1d(576, 1, kernel_size=ker, stride=strr, dilation=1, padding=0) #维度任人设置 应该是用几个核去卷，所以不涉及几何尺寸问题；ker越大 输出图越大+1；str越大 输出图越大\n",
    "        x = upconv1(x)\n",
    "        print(f'input:([1,576,32400]),kernal:{ker},stride:{strr},output:{x.shape}')  # 想要输出: torch.Size([1, 361, 720])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型占用0.0000GB\n",
      "模型占用2.1736GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1735548973083496"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from net.utils import get_model_memory\n",
    "torch.cuda.empty_cache()\n",
    "conv1 = nn.Conv1d(784, 1, kernel_size=10, stride=10, dilation=1 ,padding=0).cuda()\n",
    "get_model_memory(conv1,logger=None)\n",
    "fc1 = nn.Linear(2250, 64*45*90).cuda()\n",
    "get_model_memory(fc1,logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型占用0.0000GB\n",
      "模型占用4.3471GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.347109794616699"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from net.utils import get_model_memory\n",
    "torch.cuda.empty_cache()\n",
    "conv1 = nn.Conv1d(784, 1, kernel_size=10, stride=10, dilation=1 ,padding=0).cuda()\n",
    "get_model_memory(conv1,logger=None)\n",
    "fc1 = nn.Linear(2250, 128*45*90).cuda()\n",
    "get_model_memory(fc1,logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型占用0.0000GB\n",
      "模型占用8.6923GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.692288398742676"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from net.utils import get_model_memory\n",
    "torch.cuda.empty_cache()\n",
    "# conv1 = nn.Conv1d(784, 512, kernel_size=2, stride=2, dilation=1 ,padding=0).cuda()\n",
    "# conv2 = nn.Conv1d(512, 256, kernel_size=2, stride=2, dilation=1 ,padding=0).cuda()\n",
    "conv1 = nn.Conv1d(784, 1, kernel_size=10, stride=10, dilation=1 ,padding=0).cuda()\n",
    "get_model_memory(conv1,logger=None)\n",
    "fc1 = nn.Linear(4500, 128*45*90).cuda()\n",
    "get_model_memory(fc1,logger=None)\n",
    "\n",
    "# tic = time.time()\n",
    "# x = torch.randn(1,784,22500).to('cuda:0') #batchsize channel 长\n",
    "# print(x.shape,784*22500)\n",
    "# print(f'耗时{time.time()-tic:.4f}s')\n",
    "# tic = time.time()\n",
    "\n",
    "# x = conv1(x)\n",
    "\n",
    "# print(x.shape,x.shape[0]*x.shape[1]*x.shape[2])  # 输出: torch.Size([1, 361, 720])\n",
    "# print(f'耗时{time.time()-tic:.4f}s')\n",
    "# tic = time.time()\n",
    "\n",
    "# # x = conv2(x)\n",
    "# # print(x.shape,x.shape[0]*x.shape[1]*x.shape[2])  # 输出: torch.Size([1, 361, 720])\n",
    "# # print(f'耗时{time.time()-tic:.4f}s')\n",
    "# # tic = time.time()\n",
    "\n",
    "# x = fc1(x)\n",
    "# print(x.shape,x.shape[0]*x.shape[1]*x.shape[2])  # 输出: torch.Size([1, 361, 720])\n",
    "# print(f'耗时{time.time()-tic:.4f}s')\n",
    "# tic = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljm/anaconda3/envs/jxtnet/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 576, 22500]) 12960000\n",
      "耗时0.1405s\n",
      "torch.Size([22500, 1, 576]) 12960000\n",
      "耗时16.4928s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import time\n",
    "transformer_model = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=576, nhead=4, dim_feedforward=256),num_layers=2)\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "input_matrix = torch.randn(1, 576, 22500)  # batchsize channel 长\n",
    "print(input_matrix.shape, 576 * 22500)\n",
    "print(f'耗时{time.time() - tic:.4f}s')\n",
    "\n",
    "tic = time.time()\n",
    "output_image = input_matrix.reshape(22500,1,576) # Reshape to (seq_len, batch_size, input_channel)\n",
    "output_image = transformer_model(output_image)\n",
    "print(output_image.shape, output_image.shape[0] * output_image.shape[1] * output_image.shape[2])\n",
    "print(f'耗时{time.time() - tic:.4f}s')\n",
    "\n",
    "# fc = nn.Linear(576*22500, 22500)\n",
    "# output_image = fc(input_matrix)\n",
    "# print(output_image.shape, output_image.shape[0] * output_image.shape[1] * output_image.shape[2])\n",
    "# print(f'耗时{time.time() - tic:.4f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jxtnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
