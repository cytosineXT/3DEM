{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Similarity between (13, 20, 84, 213) (theta phi theta phi): 0.7429, dissim:0.2571\n",
      "Area Similarity between (67, 354, 92, 90) (theta phi theta phi): 0.6117, dissim:0.3883\n",
      "Area Similarity between (129, 16, 13, 285) (theta phi theta phi): 0.7368, dissim:0.2632\n",
      "Area Similarity between (139, 169, 91, 27) (theta phi theta phi): 0.8108, dissim:0.1892\n",
      "Area Similarity between (1, 316, 13, 237) (theta phi theta phi): 0.9876, dissim:0.0124\n",
      "Area Similarity between (87, 307, 25, 277) (theta phi theta phi): 0.6286, dissim:0.3714\n",
      "Area Similarity between (38, 159, 104, 10) (theta phi theta phi): 0.9918, dissim:0.0082\n",
      "Area Similarity between (114, 191, 31, 252) (theta phi theta phi): 0.9886, dissim:0.0114\n",
      "Area Similarity between (143, 84, 98, 249) (theta phi theta phi): 0.6682, dissim:0.3318\n",
      "Area Similarity between (83, 329, 122, 326) (theta phi theta phi): 0.9414, dissim:0.0586\n",
      "Area Similarity between (135, 282, 81, 120) (theta phi theta phi): 0.7637, dissim:0.2363\n",
      "Area Similarity between (155, 19, 104, 188) (theta phi theta phi): 0.9723, dissim:0.0277\n",
      "Area Similarity between (75, 143, 40, 83) (theta phi theta phi): 0.8762, dissim:0.1238\n",
      "Area Similarity between (158, 310, 14, 108) (theta phi theta phi): 0.8439, dissim:0.1561\n",
      "Area Similarity between (155, 117, 9, 4) (theta phi theta phi): 0.9469, dissim:0.0531\n",
      "Area Similarity between (163, 74, 47, 147) (theta phi theta phi): 0.7066, dissim:0.2934\n",
      "Area Similarity between (101, 22, 173, 272) (theta phi theta phi): 0.6072, dissim:0.3928\n",
      "Area Similarity between (17, 187, 80, 151) (theta phi theta phi): 0.7858, dissim:0.2142\n",
      "Area Similarity between (164, 41, 88, 109) (theta phi theta phi): 0.5892, dissim:0.4108\n",
      "Area Similarity between (145, 116, 106, 153) (theta phi theta phi): 0.8767, dissim:0.1233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nArea Difference between (3, 225, 100, 51) (theta phi theta phi): 0.0668\\nArea Difference between (113, 352, 115, 66) (theta phi theta phi): 0.0449\\nArea Difference between (79, 123, 35, 120) (theta phi theta phi): 0.0402\\nArea Difference between (92, 101, 1, 209) (theta phi theta phi): 0.0737\\nArea Difference between (95, 93, 95, 11) (theta phi theta phi): 0.0574\\nArea Difference between (106, 36, 63, 107) (theta phi theta phi): 0.0172\\nArea Difference between (150, 352, 80, 19) (theta phi theta phi): 0.0159\\nArea Difference between (140, 176, 69, 164) (theta phi theta phi): 0.0112\\nArea Difference between (167, 212, 122, 310) (theta phi theta phi): 0.0394\\nArea Difference between (126, 277, 105, 349) (theta phi theta phi): 0.0316\\nArea Difference between (120, 246, 27, 143) (theta phi theta phi): 0.0394\\nArea Difference between (27, 137, 28, 64) (theta phi theta phi): 0.0019\\nArea Difference between (115, 299, 51, 198) (theta phi theta phi): 0.0357\\nArea Difference between (74, 292, 77, 201) (theta phi theta phi): 0.0386\\nArea Difference between (148, 71, 107, 349) (theta phi theta phi): 0.0028\\nArea Difference between (123, 53, 50, 59) (theta phi theta phi): 0.0028\\nArea Difference between (170, 4, 175, 63) (theta phi theta phi): 0.0304\\nArea Difference between (117, 111, 54, 119) (theta phi theta phi): 0.0097\\nArea Difference between (175, 309, 132, 2) (theta phi theta phi): 0.0219\\nArea Difference between (104, 150, 75, 164) (theta phi theta phi): 0.0146\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "def spherical_to_cartesian(theta, phi, device=\"cpu\"):\n",
    "    \"\"\"Convert spherical coordinates (azimuth theta, elevation phi) to Cartesian coordinates.\"\"\"\n",
    "    return torch.tensor([torch.sin(phi) * torch.cos(theta),\n",
    "                         torch.sin(phi) * torch.sin(theta),\n",
    "                         torch.cos(phi)], device=device,dtype=torch.float32)\n",
    "\n",
    "def calculate_projected_area(normal, area, view_vector):\n",
    "    \"\"\"Calculate the projected area of a triangle for a given view vector.\"\"\"\n",
    "    dot_product = torch.dot(normal, view_vector)  # Scalar dot product\n",
    "    return area * torch.abs(dot_product)\n",
    "\n",
    "def calculate_angular_change_with_periodicity(theta1, phi1, theta2, phi2):\n",
    "    \"\"\"Calculate the angular change between two spherical angles, considering periodicity.\"\"\"\n",
    "    # Convert spherical coordinates into unit vectors using sin and cos for periodicity\n",
    "    x1, y1 = torch.cos(theta1), torch.sin(theta1)\n",
    "    x2, y2 = torch.cos(theta2), torch.sin(theta2)\n",
    "    # Compute angular differences considering periodicity for both azimuth and elevation\n",
    "    theta_diff = torch.acos(torch.clamp(x1 * x2 + y1 * y2, -1.0, 1.0))\n",
    "    # For elevation (phi), it's simpler as we can treat it like the azimuth\n",
    "    phi_diff = torch.abs(phi1 - phi2)\n",
    "    phi_diff = torch.minimum(phi_diff, 2 * np.pi - phi_diff)  # Wrap around periodicity for phi\n",
    "\n",
    "    return theta_diff, phi_diff\n",
    "\n",
    "def calculate_similarity(mesh, view1, view2, weight_area=0.5, weight_normals=0.5, device=\"cpu\"):\n",
    "    \"\"\"Calculate the similarity between two views based on projected areas and normal vector changes.\"\"\"\n",
    "    # Convert spherical to cartesian coordinates for both views\n",
    "    view_vector1 = spherical_to_cartesian(torch.tensor(view1[0], device=device), torch.tensor(view1[1], device=device), device=device)\n",
    "    view_vector2 = spherical_to_cartesian(torch.tensor(view2[0], device=device), torch.tensor(view2[1], device=device), device=device)\n",
    "\n",
    "    # Convert face normals and areas to PyTorch tensors and move them to GPU if necessary\n",
    "    normals = torch.tensor(mesh.face_normals, dtype=torch.float32, device=device)  # (num_faces, 3)\n",
    "    areas = torch.tensor(mesh.area_faces, dtype=torch.float32, device=device)  # (num_faces,)\n",
    "\n",
    "    # Initialize arrays for projected areas and angular changes\n",
    "    projected_areas_similarity = []\n",
    "    area_view1 = 0.\n",
    "    area_view2 = 0.\n",
    "    # Iterate through all faces (triangles)\n",
    "    for face_idx in range(len(mesh.faces)):\n",
    "        normal = normals[face_idx]  # Normal of the face\n",
    "        area = areas[face_idx]  # Area of the face\n",
    "\n",
    "        # Calculate projected areas for both views 就是算了个投影面积\n",
    "        projected_area1 = calculate_projected_area(normal, area, view_vector1)\n",
    "        projected_area2 = calculate_projected_area(normal, area, view_vector2)\n",
    "        if torch.dot(normal, view_vector1) < 0: #如果面法向量normal和方向矢量view_vector1成钝角则算入投影面积\n",
    "            area_view1 += projected_area1\n",
    "        if torch.dot(normal, view_vector2) < 0:\n",
    "            area_view2 += projected_area2\n",
    "    projected_areas_difference = torch.abs((area_view1-area_view2))\n",
    "    similarity = 1 / (1 + 10*projected_areas_difference.item())\n",
    "    similarity = max(0, min(similarity, 1)) #确保在0-1\n",
    "    dissim = 1-similarity\n",
    "    return similarity, dissim\n",
    "    # return projected_areas_difference\n",
    "\n",
    "\n",
    "# Example usage\n",
    "device = 'cuda:0'\n",
    "# Load your STL file (adjust path accordingly)\n",
    "filename = 'planes/b7fd11d4af74b4ffddaa0161e9d3dfac.obj'\n",
    "mesh = trimesh.load(filename)  # Use trimesh to load the mesh\n",
    "\n",
    "##Example view angles (azimuth and elevation in degrees)\n",
    "# views = [(30, 45, 30, 45), (30, 45, 60, 45), (30, 45, 90, 45), (30, 45, 120, 45), (30, 45, 150, 45)]\n",
    "# for view in views:\n",
    "\n",
    "viewls = []\n",
    "for i in range(20):\n",
    "    viewls.append((np.random.randint(0,180),np.random.randint(0,360),np.random.randint(0,180),np.random.randint(0,360)))\n",
    "for view in viewls:\n",
    "\n",
    "    view1 = (np.radians(view[0]), np.radians(view[1]))\n",
    "    view2 = (np.radians(view[2]), np.radians(view[3]))\n",
    "    \n",
    "    # Calculate the similarity between the two views using both projected area and normal\n",
    "    similarity, dissim= calculate_similarity(mesh, view1, view2, weight_area=0.5, weight_normals=0., device=device) #想起来应该有周期性，所以可以把单独的角度分量去掉\n",
    "    print(f\"Area Similarity between {view} (theta phi theta phi): {similarity:.4f}, dissim:{dissim:.4f}\")\n",
    "'''output\n",
    "Difference between (30, 45, 30, 45) (theta phi theta phi): 0.0000\n",
    "Difference between (30, 45, 60, 45) (theta phi theta phi): 0.0276\n",
    "Difference between (30, 45, 90, 45) (theta phi theta phi): 0.0379\n",
    "Difference between (30, 45, 120, 45) (theta phi theta phi): 0.0262\n",
    "Difference between (30, 45, 150, 45) (theta phi theta phi): 0.0022\n",
    "beta=10\n",
    "Area Similarity between (30, 45, 30, 45) (theta phi theta phi): 1.0000\n",
    "Area Similarity between (30, 45, 60, 45) (theta phi theta phi): 0.7839\n",
    "Area Similarity between (30, 45, 90, 45) (theta phi theta phi): 0.7249\n",
    "Area Similarity between (30, 45, 120, 45) (theta phi theta phi): 0.7925\n",
    "Area Similarity between (30, 45, 150, 45) (theta phi theta phi): 0.9782\n",
    "\n",
    "'''\n",
    "'''\n",
    "Area Difference between (3, 225, 100, 51) (theta phi theta phi): 0.0668\n",
    "Area Difference between (113, 352, 115, 66) (theta phi theta phi): 0.0449\n",
    "Area Difference between (79, 123, 35, 120) (theta phi theta phi): 0.0402\n",
    "Area Difference between (92, 101, 1, 209) (theta phi theta phi): 0.0737\n",
    "Area Difference between (95, 93, 95, 11) (theta phi theta phi): 0.0574\n",
    "Area Difference between (106, 36, 63, 107) (theta phi theta phi): 0.0172\n",
    "Area Difference between (150, 352, 80, 19) (theta phi theta phi): 0.0159\n",
    "Area Difference between (140, 176, 69, 164) (theta phi theta phi): 0.0112\n",
    "Area Difference between (167, 212, 122, 310) (theta phi theta phi): 0.0394\n",
    "Area Difference between (126, 277, 105, 349) (theta phi theta phi): 0.0316\n",
    "Area Difference between (120, 246, 27, 143) (theta phi theta phi): 0.0394\n",
    "Area Difference between (27, 137, 28, 64) (theta phi theta phi): 0.0019\n",
    "Area Difference between (115, 299, 51, 198) (theta phi theta phi): 0.0357\n",
    "Area Difference between (74, 292, 77, 201) (theta phi theta phi): 0.0386\n",
    "Area Difference between (148, 71, 107, 349) (theta phi theta phi): 0.0028\n",
    "Area Difference between (123, 53, 50, 59) (theta phi theta phi): 0.0028\n",
    "Area Difference between (170, 4, 175, 63) (theta phi theta phi): 0.0304\n",
    "Area Difference between (117, 111, 54, 119) (theta phi theta phi): 0.0097\n",
    "Area Difference between (175, 309, 132, 2) (theta phi theta phi): 0.0219\n",
    "Area Difference between (104, 150, 75, 164) (theta phi theta phi): 0.0146\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jxtnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
