{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mseloss原来loss=142607.2031，中值滤波后loss=141088.7031，高斯滤波后loss=140381.4688，先中值后高斯loss=139440.8281，两次中值后loss=140711.9688\n",
      "Smoothloss原来loss=177706.5469，中值滤波后loss=154292.3281，高斯滤波后loss=151825.8125，先中值后高斯loss=149060.7344，两次中值后loss=151170.3750\n",
      "torch.Size([2, 361, 720])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 1, 1, 2, 1], expected input[1, 361, 1, 2, 720] to have 1 channels, but got 361 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 109\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    108\u001b[0m tvloss \u001b[38;5;241m=\u001b[39m TVLoss()\n\u001b[0;32m--> 109\u001b[0m vt0 \u001b[38;5;241m=\u001b[39m \u001b[43mtvloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m vt1 \u001b[38;5;241m=\u001b[39m tvloss(filtered_img_median, gt)\n\u001b[1;32m    111\u001b[0m vt2 \u001b[38;5;241m=\u001b[39m tvloss(filtered_img_gaussian, gt)\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnet/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnet/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m, in \u001b[0;36mTVLoss.forward\u001b[0;34m(self, decoded, GT)\u001b[0m\n\u001b[1;32m     19\u001b[0m mse_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m loss_mse \u001b[38;5;241m=\u001b[39m mse_loss(decoded, GT)\n\u001b[0;32m---> 21\u001b[0m tvloss, G \u001b[38;5;241m=\u001b[39m \u001b[43mpytv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtv_GPU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtv_hybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmoothloss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtvloss\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,mseloss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_mse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss_mse \u001b[38;5;241m+\u001b[39m tvloss \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnet/lib/python3.9/site-packages/pytv/tv_GPU.py:84\u001b[0m, in \u001b[0;36mtv_hybrid\u001b[0;34m(img, mask, reg_z_over_reg, reg_time, mask_static, factor_reg_static, return_pytorch_tensor, return_grad_norms)\u001b[0m\n\u001b[1;32m     81\u001b[0m Nz \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     82\u001b[0m M \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 84\u001b[0m D_img \u001b[38;5;241m=\u001b[39m \u001b[43mpytv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtv_operators_GPU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD_hybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_z_over_reg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg_z_over_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_static\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask_static\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_reg_static\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfactor_reg_static\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_pytorch_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m tv, grad_norms \u001b[38;5;241m=\u001b[39m pytv\u001b[38;5;241m.\u001b[39mtv_operators_GPU\u001b[38;5;241m.\u001b[39mcompute_L21_norm(D_img, return_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# When non-differentiable, set to 0.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnet/lib/python3.9/site-packages/pytv/tv_operators_GPU.py:200\u001b[0m, in \u001b[0;36mD_hybrid\u001b[0;34m(img, reg_z_over_reg, reg_time, mask_static, factor_reg_static, return_pytorch_tensor)\u001b[0m\n\u001b[1;32m    196\u001b[0m kernel_slice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(np\u001b[38;5;241m.\u001b[39mreshape(kernel_slice, (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m+\u001b[39mkernel_slice\u001b[38;5;241m.\u001b[39mshape))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# The intensity differences across rows (Upwind / Forward)\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# (Transpose to switch M and Nz)\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m D_img[:, \u001b[38;5;241m0\u001b[39m, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m, :, :, :], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# The intensity differences across columns (Upwind / Forward)\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# (Transpose to switch M and Nz)\u001b[39;00m\n\u001b[1;32m    204\u001b[0m D_img[:, \u001b[38;5;241m1\u001b[39m, :, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mconv3d(img_tensor, kernel_col, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)[:, \u001b[38;5;241m0\u001b[39m, :, :, :], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 1, 1, 2, 1], expected input[1, 361, 1, 2, 720] to have 1 channels, but got 361 channels instead"
     ]
    }
   ],
   "source": [
    "import pytv  \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, beta=1.0):\n",
    "        super(TVLoss, self).__init__()\n",
    "        # self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, decoded, GT):\n",
    "        # Calculate the MSE loss\n",
    "        mse_loss = nn.MSELoss(reduction='sum')\n",
    "        loss_mse = mse_loss(decoded, GT)\n",
    "        tvloss, G = pytv.tv_GPU.tv_hybrid(decoded)\n",
    "        print(f\"smoothloss:{tvloss*self.beta:.4f},mseloss:{loss_mse:.4f}\")\n",
    "        total_loss = loss_mse + tvloss * self.beta\n",
    "        return total_loss\n",
    "\n",
    "class SmoothLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, beta=1.0):\n",
    "        super(SmoothLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, decoded, GT):\n",
    "        # Calculate the MSE loss\n",
    "        mse_loss = nn.MSELoss(reduction='sum')\n",
    "        loss_mse = mse_loss(decoded, GT)\n",
    "\n",
    "        diff1 = torch.abs(decoded[:,  :-1, :] - decoded[:,  1:, :])\n",
    "        diff2 = torch.abs(decoded[:,  :, :-1] - decoded[:,  :, 1:])\n",
    "        smoothness_loss = torch.sum(diff1) + torch.sum(diff2) * self.alpha\n",
    "        # print(f\"smoothloss:{smoothness_loss*self.beta:.4f},mseloss:{loss_mse:.4f}\")\n",
    "        total_loss = loss_mse + smoothness_loss * self.beta\n",
    "        return total_loss\n",
    "\n",
    "def median_filter2d(img, kernel_size=5):\n",
    "    pad_size = kernel_size // 2    # 计算 padding 大小\n",
    "    img_padded = F.pad(img, (pad_size, pad_size, pad_size, pad_size), mode='reflect')    # 对图像进行 padding\n",
    "    batch_size, channels, height, width = img_padded.shape    # 获取图像的尺寸\n",
    "    unfolded = F.unfold(img_padded, kernel_size=kernel_size)    # 展开图像矩阵\n",
    "    unfolded = unfolded.view(batch_size, channels, kernel_size * kernel_size, -1)    # 计算中值\n",
    "    median = unfolded.median(dim=2)[0]\n",
    "    median = median.view(batch_size, channels, height - 2 * pad_size, width - 2 * pad_size)    # 恢复图像尺寸\n",
    "    return median\n",
    "\n",
    "def gaussian_kernel(size, sigma):\n",
    "    \"\"\"生成一个高斯核\"\"\"\n",
    "    kernel = torch.tensor([[(1/(2.0*np.pi*sigma**2)) * np.exp(-((x - size//2)**2 + (y - size//2)**2)/(2*sigma**2))\n",
    "                            for x in range(size)] for y in range(size)]).float()\n",
    "    kernel /= kernel.sum()\n",
    "    return kernel.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "def gaussian_filter2d(img, kernel_size=5, sigma=1.0):\n",
    "    \"\"\"应用高斯滤波\"\"\"\n",
    "    kernel = gaussian_kernel(kernel_size, sigma)\n",
    "    channels = img.shape[1]\n",
    "    kernel = kernel.repeat(channels, 1, 1, 1)\n",
    "    padding = kernel_size // 2\n",
    "    filtered_img = F.conv2d(img, kernel, padding=padding, groups=channels)\n",
    "    return filtered_img\n",
    "\n",
    "# 加载图像\n",
    "decoded = torch.load('decoded2.pt').cpu()\n",
    "gt = torch.load('gt2.pt').cpu()\n",
    "\n",
    "sigma = 4.\n",
    "# 假设图像是灰度图，转换形状为 [batch_size, channels, height, width]\n",
    "# 这里的 decoded 是 [2, 361, 720]，我们假设 batch_size = 2，channels = 1\n",
    "img = torch.Tensor(decoded).unsqueeze(1)  # 添加 channel 维度\n",
    "filtered_img_median = median_filter2d(img, kernel_size=5)# 应用中值滤波\n",
    "filtered_img_gaussian = gaussian_filter2d(img, kernel_size=5, sigma=sigma)# 应用高斯滤波\n",
    "bothMG_img = gaussian_filter2d(filtered_img_median, kernel_size=5, sigma=sigma)#两个都用 这个效果好\n",
    "bothGM_img = median_filter2d(filtered_img_median, kernel_size=5)#两个都用\n",
    "\n",
    "# 移除 batch 和 channel 维度\n",
    "img = img.squeeze(1)\n",
    "filtered_img_median = filtered_img_median.squeeze(1)\n",
    "filtered_img_gaussian = filtered_img_gaussian.squeeze(1)\n",
    "bothMG_img = bothMG_img.squeeze(1)\n",
    "bothGM_img = bothGM_img.squeeze(1)\n",
    "gt = torch.Tensor(gt).squeeze(1)  # 确保 gt 形状正确\n",
    "\n",
    "mseloss = torch.nn.MSELoss(reduction='sum')\n",
    "loss0 = mseloss(img, gt)\n",
    "loss1 = mseloss(filtered_img_median, gt)\n",
    "loss2 = mseloss(filtered_img_gaussian, gt)\n",
    "loss3 = mseloss(bothMG_img,gt)\n",
    "loss4 = mseloss(bothGM_img,gt)\n",
    "print(f'Mseloss原来loss={loss0:.4f}，中值滤波后loss={loss1:.4f}，高斯滤波后loss={loss2:.4f}，先中值后高斯loss={loss3:.4f}，两次中值后loss={loss4:.4f}')\n",
    "\n",
    "smloss = SmoothLoss()\n",
    "smloss0 = smloss(img, gt)\n",
    "smloss1 = smloss(filtered_img_median, gt)\n",
    "smloss2 = smloss(filtered_img_gaussian, gt)\n",
    "smloss3 = smloss(bothMG_img,gt)\n",
    "smloss4 = smloss(bothGM_img,gt)\n",
    "print(f'Smoothloss原来loss={smloss0:.4f}，中值滤波后loss={smloss1:.4f}，高斯滤波后loss={smloss2:.4f}，先中值后高斯loss={smloss3:.4f}，两次中值后loss={smloss4:.4f}')\n",
    "\n",
    "print(img.shape)\n",
    "tvloss = TVLoss()\n",
    "vt0 = tvloss(img, gt)\n",
    "vt1 = tvloss(filtered_img_median, gt)\n",
    "vt2 = tvloss(filtered_img_gaussian, gt)\n",
    "vt3 = tvloss(bothMG_img,gt)\n",
    "vt4 = tvloss(bothGM_img,gt)\n",
    "print(f'TVloss原来loss={smloss0:.4f}，中值滤波后loss={smloss1:.4f}，高斯滤波后loss={smloss2:.4f}，先中值后高斯loss={smloss3:.4f}，两次中值后loss={smloss4:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jxtnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
