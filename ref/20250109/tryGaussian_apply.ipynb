{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型占用0.0075GB\n",
      "Output shape: torch.Size([10, 1, 720, 360])\n",
      "tensor([[[[6.2354, 6.3076, 6.3802,  ..., 6.4246, 6.3517, 6.2791],\n",
      "          [6.2712, 6.3438, 6.4168,  ..., 6.4608, 6.3874, 6.3145],\n",
      "          [6.3071, 6.3801, 6.4535,  ..., 6.4971, 6.4233, 6.3499],\n",
      "          ...,\n",
      "          [6.6159, 6.6910, 6.7666,  ..., 6.3335, 6.2600, 6.1870],\n",
      "          [6.5792, 6.6539, 6.7291,  ..., 6.2976, 6.2246, 6.1520],\n",
      "          [6.5426, 6.6169, 6.6917,  ..., 6.2619, 6.1893, 6.1171]]],\n",
      "\n",
      "\n",
      "        [[[6.2629, 6.3355, 6.4086,  ..., 6.6752, 6.6008, 6.5267],\n",
      "          [6.2983, 6.3714, 6.4448,  ..., 6.7122, 6.6374, 6.5629],\n",
      "          [6.3338, 6.4073, 6.4812,  ..., 6.7494, 6.6741, 6.5992],\n",
      "          ...,\n",
      "          [6.6032, 6.6781, 6.7534,  ..., 6.5245, 6.4505, 6.3770],\n",
      "          [6.5670, 6.6415, 6.7164,  ..., 6.4878, 6.4142, 6.3411],\n",
      "          [6.5310, 6.6050, 6.6794,  ..., 6.4512, 6.3781, 6.3054]]],\n",
      "\n",
      "\n",
      "        [[[6.2888, 6.3602, 6.4321,  ..., 6.8231, 6.7489, 6.6751],\n",
      "          [6.3249, 6.3968, 6.4690,  ..., 6.8610, 6.7864, 6.7121],\n",
      "          [6.3611, 6.4334, 6.5061,  ..., 6.8990, 6.8239, 6.7492],\n",
      "          ...,\n",
      "          [6.6409, 6.7146, 6.7887,  ..., 6.2827, 6.2117, 6.1410],\n",
      "          [6.6042, 6.6774, 6.7511,  ..., 6.2465, 6.1758, 6.1056],\n",
      "          [6.5675, 6.6404, 6.7136,  ..., 6.2103, 6.1401, 6.0703]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[6.2080, 6.2796, 6.3515,  ..., 6.5421, 6.4691, 6.3964],\n",
      "          [6.2439, 6.3158, 6.3882,  ..., 6.5792, 6.5057, 6.4326],\n",
      "          [6.2798, 6.3522, 6.4249,  ..., 6.6163, 6.5424, 6.4689],\n",
      "          ...,\n",
      "          [6.6763, 6.7511, 6.8264,  ..., 6.4516, 6.3782, 6.3052],\n",
      "          [6.6394, 6.7138, 6.7887,  ..., 6.4149, 6.3419, 6.2693],\n",
      "          [6.6026, 6.6766, 6.7510,  ..., 6.3783, 6.3057, 6.2336]]],\n",
      "\n",
      "\n",
      "        [[[6.2192, 6.2909, 6.3630,  ..., 6.5875, 6.5139, 6.4407],\n",
      "          [6.2546, 6.3266, 6.3991,  ..., 6.6245, 6.5505, 6.4769],\n",
      "          [6.2900, 6.3625, 6.4354,  ..., 6.6617, 6.5872, 6.5132],\n",
      "          ...,\n",
      "          [6.5256, 6.5999, 6.6746,  ..., 6.5832, 6.5088, 6.4347],\n",
      "          [6.4896, 6.5636, 6.6379,  ..., 6.5461, 6.4721, 6.3985],\n",
      "          [6.4538, 6.5273, 6.6013,  ..., 6.5091, 6.4355, 6.3623]]],\n",
      "\n",
      "\n",
      "        [[[6.2779, 6.3500, 6.4226,  ..., 6.7344, 6.6600, 6.5859],\n",
      "          [6.3137, 6.3862, 6.4591,  ..., 6.7722, 6.6974, 6.6229],\n",
      "          [6.3495, 6.4225, 6.4958,  ..., 6.8101, 6.7348, 6.6599],\n",
      "          ...,\n",
      "          [6.4870, 6.5597, 6.6328,  ..., 6.4477, 6.3749, 6.3026],\n",
      "          [6.4508, 6.5231, 6.5958,  ..., 6.4109, 6.3386, 6.2667],\n",
      "          [6.4147, 6.4866, 6.5589,  ..., 6.3743, 6.3024, 6.2309]]]],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from net.utils import get_model_memory_nolog\n",
    "# Define the MLP Gaussian Decoder\n",
    "class MLP_GaussianDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_gaussians):\n",
    "        super().__init__()\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.conv1d1 = nn.Conv1d(576, 12, kernel_size=1, stride=1, dilation=1 ,padding=0) #[351,576]-[351,96]\n",
    "        # MLP to generate Gaussian parameters\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),  # Input -> hidden layer 0.30G\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),       # Hidden -> hidden\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_gaussians * 6)  # Hidden -> Gaussian parameters\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # [281, 10, 576]\n",
    "        \"\"\"\n",
    "        z: Input encoded vector of shape [batch, length, channel]\n",
    "        Returns: Decoded Gaussian-based image of shape [batch, output_h, output_w]\n",
    "        \"\"\"\n",
    "        \n",
    "        x = x.reshape(x.shape[1], x.shape[2], -1)  # 1DConv输入：Reshape to (batch_size, input_channel, seq_len) [10, 576, 281]\n",
    "        batch_size, channel, length = x.shape\n",
    "        x = self.conv1d1(x) #576变12 [10, 12, 281]\n",
    "\n",
    "        # Flatten the input for MLP (combine length and channel dimensions)\n",
    "        x_flat = x.view(batch_size, -1)  # Shape: [batch, length * 12channel] [10, 3372]\n",
    "\n",
    "        # Generate Gaussian parameters\n",
    "        params = self.mlp(x_flat)  # Shape: [batch, num_gaussians * 6] [10, 600]\n",
    "        params = params.view(batch_size, self.num_gaussians, 6)  # [batch, num_gaussians, 6] [10, 100, 6]\n",
    "\n",
    "        # Separate Gaussian parameters: x, y, sigma_x, sigma_y, rho, intensity\n",
    "        xc, yc, sigma_x, sigma_y, rho, intensity = torch.chunk(params, 6, dim=-1)\n",
    "\n",
    "        # Normalize xc, yc to [-1, 1] (image coordinate range)\n",
    "        xc = torch.tanh(xc)\n",
    "        yc = torch.tanh(yc)\n",
    "\n",
    "        # Ensure sigma_x, sigma_y > 0 (use softplus activation)\n",
    "        sigma_x = F.softplus(sigma_x) + 1e-6\n",
    "        sigma_y = F.softplus(sigma_y) + 1e-6\n",
    "\n",
    "        # Ensure rho is within a valid range [-1, 1] (correlation coefficient)\n",
    "        rho = torch.tanh(rho)\n",
    "\n",
    "        # Intensity can be scaled to [0, 1] using sigmoid\n",
    "        intensity = torch.sigmoid(intensity)\n",
    "\n",
    "        # Create a 2D grid for the output image\n",
    "        x = torch.linspace(-1, 1, 720, device=x.device)\n",
    "        y = torch.linspace(-1, 1, 360, device=x.device)\n",
    "        X, Y = torch.meshgrid(x, y, indexing=\"ij\")  # X, Y shape: [output_w, output_h]\n",
    "\n",
    "        # Expand X, Y to support broadcasting across batches and gaussians\n",
    "        X = X.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, output_w, output_h]\n",
    "        Y = Y.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, output_w, output_h]\n",
    "\n",
    "        # Expand Gaussian parameters to match grid dimensions\n",
    "        xc = xc.unsqueeze(-1).unsqueeze(-1)  # [batch, num_gaussians, 1, 1]\n",
    "        yc = yc.unsqueeze(-1).unsqueeze(-1)\n",
    "        sigma_x = sigma_x.unsqueeze(-1).unsqueeze(-1)\n",
    "        sigma_y = sigma_y.unsqueeze(-1).unsqueeze(-1)\n",
    "        rho = rho.unsqueeze(-1).unsqueeze(-1)\n",
    "        intensity = intensity.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # Compute Gaussian function for all Gaussians in parallel\n",
    "        X_diff = X - xc  # [batch, num_gaussians, output_w, output_h]\n",
    "        Y_diff = Y - yc  # [batch, num_gaussians, output_w, output_h]\n",
    "\n",
    "        gaussians = intensity * torch.exp(\n",
    "            -(\n",
    "                (X_diff ** 2) / (2 * sigma_x ** 2)\n",
    "                + (Y_diff ** 2) / (2 * sigma_y ** 2)\n",
    "                + rho * (X_diff * Y_diff) / (sigma_x * sigma_y)\n",
    "            )\n",
    "        )  # [batch, num_gaussians, output_w, output_h]\n",
    "\n",
    "        # Sum over all Gaussians\n",
    "        output = gaussians.sum(dim=1)  # Shape: [batch, output_w, output_h]\n",
    "\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 10\n",
    "length = 281\n",
    "channel = 576\n",
    "num_gaussians = 100  # Number of Gaussians\n",
    "\n",
    "\n",
    "# Input encoded vector (randomly generated)\n",
    "encoded = torch.randn(length, batch_size, channel)  # Shape: [281, 10, 576]\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder = MLP_GaussianDecoder(input_dim=length * 12, num_gaussians=num_gaussians)\n",
    "get_model_memory_nolog(decoder)\n",
    "# Forward pass\n",
    "output = decoder(encoded)  # Shape: [10, 360, 720]\n",
    "\n",
    "# Print output shape\n",
    "print(\"Output shape:\", output.shape)  # Should be [10, 360, 720]\n",
    "\n",
    "print(output)\n",
    "#怎么output不一样了。。我笑死 不过好像问题不大，只要形状对上，能训练就行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jxtnett",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
