{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型占用0.7276GB\n",
      "Output shape: torch.Size([10, 360, 720])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from net.utils import get_model_memory_nolog\n",
    "# Define the MLP Gaussian Decoder\n",
    "class MLP_GaussianDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_gaussians, output_h, output_w):\n",
    "        super().__init__()\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.output_h = output_h\n",
    "        self.output_w = output_w\n",
    "        \n",
    "        # MLP to generate Gaussian parameters\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_gaussians * 6 *2),  # Input -> hidden layer 0.72G\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(num_gaussians * 6 *2, num_gaussians * 6),       # Hidden -> hidden\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(num_gaussians * 6, num_gaussians * 6)  # Hidden -> Gaussian parameters\n",
    "        )\n",
    "        #     nn.Linear(input_dim, 512),  # Input -> hidden layer 0.30G\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(512, 256),       # Hidden -> hidden\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(256, num_gaussians * 6)  # Hidden -> Gaussian parameters\n",
    "        # )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z: Input encoded vector of shape [batch, length, channel]\n",
    "        Returns: Decoded Gaussian-based image of shape [batch, output_h, output_w]\n",
    "        \"\"\"\n",
    "        batch_size, length, channel = z.shape\n",
    "\n",
    "        # Flatten the input for MLP (combine length and channel dimensions)\n",
    "        z_flat = z.view(batch_size, -1)  # Shape: [batch, length * channel]\n",
    "\n",
    "        # Generate Gaussian parameters\n",
    "        params = self.mlp(z_flat)  # Shape: [batch, num_gaussians * 6]\n",
    "        params = params.view(batch_size, self.num_gaussians, 6)  # [batch, num_gaussians, 6]\n",
    "\n",
    "        # Separate Gaussian parameters: x, y, sigma_x, sigma_y, rho, intensity\n",
    "        xc, yc, sigma_x, sigma_y, rho, intensity = torch.chunk(params, 6, dim=-1)\n",
    "\n",
    "        # Normalize xc, yc to [-1, 1] (image coordinate range)\n",
    "        xc = torch.tanh(xc)\n",
    "        yc = torch.tanh(yc)\n",
    "\n",
    "        # Ensure sigma_x, sigma_y > 0 (use softplus activation)\n",
    "        sigma_x = F.softplus(sigma_x) + 1e-6\n",
    "        sigma_y = F.softplus(sigma_y) + 1e-6\n",
    "\n",
    "        # Ensure rho is within a valid range [-1, 1] (correlation coefficient)\n",
    "        rho = torch.tanh(rho)\n",
    "\n",
    "        # Intensity can be scaled to [0, 1] using sigmoid\n",
    "        intensity = torch.sigmoid(intensity)\n",
    "\n",
    "        # Create a 2D grid for the output image\n",
    "        x = torch.linspace(-1, 1, self.output_w, device=z.device)\n",
    "        y = torch.linspace(-1, 1, self.output_h, device=z.device)\n",
    "        X, Y = torch.meshgrid(x, y, indexing=\"ij\")  # X, Y shape: [output_w, output_h]\n",
    "\n",
    "        # Expand X, Y to match batch and num_gaussians dimensions\n",
    "        X = X.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, output_w, output_h]\n",
    "        Y = Y.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, output_w, output_h]\n",
    "\n",
    "        # Initialize an empty output image\n",
    "        output = torch.zeros(batch_size, self.output_h, self.output_w, device=z.device)\n",
    "\n",
    "        # Loop over each batch to generate the Gaussian-based image\n",
    "        for b in range(batch_size):\n",
    "            gaussian_map = torch.zeros(self.output_h, self.output_w, device=z.device)\n",
    "            for i in range(self.num_gaussians):\n",
    "                # Extract parameters for the current Gaussian\n",
    "                x_c, y_c = xc[b, i], yc[b, i]\n",
    "                sig_x, sig_y = sigma_x[b, i], sigma_y[b, i]\n",
    "                p_rho = rho[b, i]\n",
    "                inten = intensity[b, i]\n",
    "\n",
    "                # Compute Gaussian function\n",
    "                gaussian = inten * torch.exp(\n",
    "                    -(\n",
    "                        ((X - x_c) ** 2) / (2 * sig_x ** 2)\n",
    "                        + ((Y - y_c) ** 2) / (2 * sig_y ** 2)\n",
    "                        + p_rho * (X - x_c) * (Y - y_c) / (sig_x * sig_y)\n",
    "                    )\n",
    "                )\n",
    "                gaussian_map += gaussian.squeeze().t()  # Add to the final map\n",
    "            output[b] = gaussian_map\n",
    "\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 10\n",
    "length = 281\n",
    "channel = 576\n",
    "num_gaussians = 100  # Number of Gaussians\n",
    "output_h = 360       # Height of output image\n",
    "output_w = 720       # Width of output image\n",
    "\n",
    "# Input encoded vector (randomly generated)\n",
    "encoded = torch.randn(batch_size, length, channel)  # Shape: [10, 281, 576]\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder = MLP_GaussianDecoder(input_dim=length * channel, num_gaussians=num_gaussians, output_h=output_h, output_w=output_w)\n",
    "get_model_memory_nolog(decoder)\n",
    "# Forward pass\n",
    "output = decoder(encoded)  # Shape: [10, 360, 720]\n",
    "\n",
    "# Print output shape\n",
    "print(\"Output shape:\", output.shape)  # Should be [10, 360, 720]\n",
    "\n",
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[6.5424, 6.5797, 6.6170,  ..., 6.4938, 6.4569, 6.4200],\n",
      "         [6.6159, 6.6536, 6.6913,  ..., 6.5673, 6.5299, 6.4927],\n",
      "         [6.6898, 6.7279, 6.7660,  ..., 6.6412, 6.6034, 6.5657],\n",
      "         ...,\n",
      "         [6.3503, 6.3867, 6.4232,  ..., 6.5373, 6.5006, 6.4640],\n",
      "         [6.2784, 6.3144, 6.3505,  ..., 6.4641, 6.4278, 6.3916],\n",
      "         [6.2070, 6.2426, 6.2782,  ..., 6.3913, 6.3554, 6.3197]],\n",
      "\n",
      "        [[6.3316, 6.3672, 6.4028,  ..., 6.1968, 6.1617, 6.1267],\n",
      "         [6.4046, 6.4405, 6.4765,  ..., 6.2687, 6.2332, 6.1978],\n",
      "         [6.4779, 6.5143, 6.5507,  ..., 6.3410, 6.3051, 6.2692],\n",
      "         ...,\n",
      "         [6.7817, 6.8203, 6.8590,  ..., 6.8897, 6.8510, 6.8124],\n",
      "         [6.7065, 6.7446, 6.7829,  ..., 6.8140, 6.7757, 6.7376],\n",
      "         [6.6317, 6.6694, 6.7073,  ..., 6.7387, 6.7009, 6.6631]],\n",
      "\n",
      "        [[6.2473, 6.2832, 6.3192,  ..., 6.4367, 6.4003, 6.3641],\n",
      "         [6.3195, 6.3558, 6.3923,  ..., 6.5099, 6.4732, 6.4365],\n",
      "         [6.3921, 6.4289, 6.4657,  ..., 6.5836, 6.5464, 6.5094],\n",
      "         ...,\n",
      "         [6.6289, 6.6663, 6.7038,  ..., 6.4625, 6.4257, 6.3889],\n",
      "         [6.5549, 6.5919, 6.6290,  ..., 6.3896, 6.3531, 6.3168],\n",
      "         [6.4813, 6.5179, 6.5545,  ..., 6.3170, 6.2810, 6.2451]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[6.3103, 6.3462, 6.3823,  ..., 6.1638, 6.1283, 6.0929],\n",
      "         [6.3829, 6.4192, 6.4557,  ..., 6.2346, 6.1988, 6.1630],\n",
      "         [6.4559, 6.4927, 6.5296,  ..., 6.3059, 6.2696, 6.2335],\n",
      "         ...,\n",
      "         [6.6676, 6.7057, 6.7438,  ..., 6.5295, 6.4919, 6.4545],\n",
      "         [6.5937, 6.6313, 6.6691,  ..., 6.4570, 6.4198, 6.3828],\n",
      "         [6.5202, 6.5574, 6.5947,  ..., 6.3849, 6.3482, 6.3115]],\n",
      "\n",
      "        [[6.3073, 6.3435, 6.3798,  ..., 6.2411, 6.2053, 6.1696],\n",
      "         [6.3794, 6.4160, 6.4527,  ..., 6.3127, 6.2765, 6.2404],\n",
      "         [6.4519, 6.4889, 6.5260,  ..., 6.3848, 6.3481, 6.3116],\n",
      "         ...,\n",
      "         [6.5093, 6.5467, 6.5842,  ..., 6.5687, 6.5311, 6.4937],\n",
      "         [6.4364, 6.4734, 6.5105,  ..., 6.4954, 6.4583, 6.4213],\n",
      "         [6.3640, 6.4005, 6.4372,  ..., 6.4226, 6.3859, 6.3493]],\n",
      "\n",
      "        [[6.3434, 6.3796, 6.4159,  ..., 6.4716, 6.4353, 6.3991],\n",
      "         [6.4162, 6.4528, 6.4896,  ..., 6.5453, 6.5086, 6.4720],\n",
      "         [6.4894, 6.5265, 6.5637,  ..., 6.6194, 6.5823, 6.5452],\n",
      "         ...,\n",
      "         [6.4278, 6.4646, 6.5016,  ..., 6.4631, 6.4264, 6.3898],\n",
      "         [6.3551, 6.3915, 6.4281,  ..., 6.3902, 6.3539, 6.3176],\n",
      "         [6.2828, 6.3188, 6.3550,  ..., 6.3177, 6.2818, 6.2460]]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型占用0.7276GB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 108\u001b[0m\n\u001b[1;32m    106\u001b[0m get_model_memory_nolog(decoder)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m output \u001b[38;5;241m=\u001b[39m decoder(\u001b[43mencoded\u001b[49m)  \u001b[38;5;66;03m# Shape: [10, 360, 720]\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Print output shape\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Should be [10, 360, 720]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoded' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from net.utils import get_model_memory_nolog\n",
    "# Define the MLP Gaussian Decoder\n",
    "class MLP_GaussianDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_gaussians, output_h, output_w):\n",
    "        super().__init__()\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.output_h = output_h\n",
    "        self.output_w = output_w\n",
    "        \n",
    "        # MLP to generate Gaussian parameters\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_gaussians * 6 *2),  # Input -> hidden layer 0.72G\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(num_gaussians * 6 *2, num_gaussians * 6),       # Hidden -> hidden\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(num_gaussians * 6, num_gaussians * 6)  # Hidden -> Gaussian parameters\n",
    "        )\n",
    "        #     nn.Linear(input_dim, 512),  # Input -> hidden layer 0.30G\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(512, 256),       # Hidden -> hidden\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(256, num_gaussians * 6)  # Hidden -> Gaussian parameters\n",
    "        # )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z: Input encoded vector of shape [batch, length, channel]\n",
    "        Returns: Decoded Gaussian-based image of shape [batch, output_h, output_w]\n",
    "        \"\"\"\n",
    "        batch_size, length, channel = z.shape\n",
    "\n",
    "        # Flatten the input for MLP (combine length and channel dimensions)\n",
    "        z_flat = z.view(batch_size, -1)  # Shape: [batch, length * channel]\n",
    "\n",
    "        # Generate Gaussian parameters\n",
    "        params = self.mlp(z_flat)  # Shape: [batch, num_gaussians * 6]\n",
    "        params = params.view(batch_size, self.num_gaussians, 6)  # [batch, num_gaussians, 6]\n",
    "\n",
    "        # Separate Gaussian parameters: x, y, sigma_x, sigma_y, rho, intensity\n",
    "        xc, yc, sigma_x, sigma_y, rho, intensity = torch.chunk(params, 6, dim=-1)\n",
    "\n",
    "        # Normalize xc, yc to [-1, 1] (image coordinate range)\n",
    "        xc = torch.tanh(xc)\n",
    "        yc = torch.tanh(yc)\n",
    "\n",
    "        # Ensure sigma_x, sigma_y > 0 (use softplus activation)\n",
    "        sigma_x = F.softplus(sigma_x) + 1e-6\n",
    "        sigma_y = F.softplus(sigma_y) + 1e-6\n",
    "\n",
    "        # Ensure rho is within a valid range [-1, 1] (correlation coefficient)\n",
    "        rho = torch.tanh(rho)\n",
    "\n",
    "        # Intensity can be scaled to [0, 1] using sigmoid\n",
    "        intensity = torch.sigmoid(intensity)\n",
    "\n",
    "        # Create a 2D grid for the output image\n",
    "        x = torch.linspace(-1, 1, self.output_w, device=z.device)\n",
    "        y = torch.linspace(-1, 1, self.output_h, device=z.device)\n",
    "        X, Y = torch.meshgrid(x, y, indexing=\"ij\")  # X, Y shape: [output_w, output_h]\n",
    "\n",
    "        # Expand X, Y to support broadcasting across batches and gaussians\n",
    "        X = X.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, output_w, output_h]\n",
    "        Y = Y.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, output_w, output_h]\n",
    "\n",
    "        # Expand Gaussian parameters to match grid dimensions\n",
    "        xc = xc.unsqueeze(-1).unsqueeze(-1)  # [batch, num_gaussians, 1, 1]\n",
    "        yc = yc.unsqueeze(-1).unsqueeze(-1)\n",
    "        sigma_x = sigma_x.unsqueeze(-1).unsqueeze(-1)\n",
    "        sigma_y = sigma_y.unsqueeze(-1).unsqueeze(-1)\n",
    "        rho = rho.unsqueeze(-1).unsqueeze(-1)\n",
    "        intensity = intensity.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # Compute Gaussian function for all Gaussians in parallel\n",
    "        X_diff = X - xc  # [batch, num_gaussians, output_w, output_h]\n",
    "        Y_diff = Y - yc  # [batch, num_gaussians, output_w, output_h]\n",
    "\n",
    "        gaussians = intensity * torch.exp(\n",
    "            -(\n",
    "                (X_diff ** 2) / (2 * sigma_x ** 2)\n",
    "                + (Y_diff ** 2) / (2 * sigma_y ** 2)\n",
    "                + rho * (X_diff * Y_diff) / (sigma_x * sigma_y)\n",
    "            )\n",
    "        )  # [batch, num_gaussians, output_w, output_h]\n",
    "\n",
    "        # Sum over all Gaussians\n",
    "        output = gaussians.sum(dim=1)  # Shape: [batch, output_w, output_h]\n",
    "\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 10\n",
    "length = 281\n",
    "channel = 576\n",
    "num_gaussians = 100  # Number of Gaussians\n",
    "output_h = 360       # Height of output image\n",
    "output_w = 720       # Width of output image\n",
    "\n",
    "# Input encoded vector (randomly generated)\n",
    "# encoded = torch.randn(batch_size, length, channel)  # Shape: [10, 281, 576]\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder = MLP_GaussianDecoder(input_dim=length * channel, num_gaussians=num_gaussians, output_h=output_h, output_w=output_w)\n",
    "get_model_memory_nolog(decoder)\n",
    "# Forward pass\n",
    "output = decoder(encoded)  # Shape: [10, 360, 720]\n",
    "\n",
    "# Print output shape\n",
    "print(\"Output shape:\", output.shape)  # Should be [10, 360, 720]\n",
    "\n",
    "print(output)\n",
    "#怎么output不一样了。。我笑死 不过好像问题不大，只要形状对上，能训练就行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型占用2.2069GB\n",
      "num_gaussians: 300, Model Memory: 2.21 GB, Forward Time: 8.2478 s\n",
      "模型占用2.9586GB\n",
      "num_gaussians: 400, Model Memory: 2.96 GB, Forward Time: 8.1051 s\n",
      "模型占用3.7184GB\n",
      "num_gaussians: 500, Model Memory: 3.72 GB, Forward Time: 11.7652 s\n",
      "模型占用4.4862GB\n",
      "num_gaussians: 600, Model Memory: 4.49 GB, Forward Time: 15.4920 s\n",
      "模型占用7.6379GB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 10\n",
    "length = 281\n",
    "channel = 576\n",
    "output_h = 360\n",
    "output_w = 720\n",
    "device=torch.device('cuda:0')\n",
    "# Input encoded vector (randomly generated)\n",
    "encoded = torch.randn(batch_size, length, channel)  # Shape: [10, 281, 576]\n",
    "\n",
    "# Range of num_gaussians to test\n",
    "num_gaussians_list = [300, 400, 500, 600, 1000] #1000在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。 根本就用不了。。\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "for num_gaussians in num_gaussians_list:\n",
    "    # Initialize the decoder with current num_gaussians\n",
    "    decoder = MLP_GaussianDecoder(input_dim=length * channel, num_gaussians=num_gaussians, output_h=output_h, output_w=output_w)\n",
    "\n",
    "    # Measure model size\n",
    "    model_memory = get_model_memory_nolog(decoder)\n",
    "\n",
    "    # Measure forward pass time\n",
    "    start_time = time.time()\n",
    "    output = decoder(encoded)  # Forward pass\n",
    "    end_time = time.time()\n",
    "    forward_time = end_time - start_time\n",
    "\n",
    "    # Record results\n",
    "    results.append((num_gaussians, model_memory, forward_time))\n",
    "    print(f\"num_gaussians: {num_gaussians}, Model Memory: {model_memory:.2f} GB, Forward Time: {forward_time:.4f} s\")\n",
    "\n",
    "# Print all results\n",
    "print(\"\\nResults Summary:\")\n",
    "for num_gaussians, model_memory, forward_time in results:\n",
    "    print(f\"num_gaussians: {num_gaussians}, Model Memory: {model_memory:.2f} GB, Forward Time: {forward_time:.4f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型占用0.3093GB\n",
      "num_gaussians: 10, Model Memory: 0.31 GB, Forward Time: 0.0017 s\n",
      "模型占用0.3095GB\n",
      "num_gaussians: 50, Model Memory: 0.31 GB, Forward Time: 0.0063 s\n",
      "模型占用0.3098GB\n",
      "num_gaussians: 100, Model Memory: 0.31 GB, Forward Time: 0.0035 s\n",
      "模型占用0.3104GB\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.93 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 119\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Measure forward pass time\u001b[39;00m\n\u001b[1;32m    118\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 119\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m    120\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    121\u001b[0m forward_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnett/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnett/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 83\u001b[0m, in \u001b[0;36mMLP_GaussianDecoder.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     78\u001b[0m X_diff \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m-\u001b[39m xc  \u001b[38;5;66;03m# [batch, num_gaussians, output_w, output_h]\u001b[39;00m\n\u001b[1;32m     79\u001b[0m Y_diff \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m-\u001b[39m yc  \u001b[38;5;66;03m# [batch, num_gaussians, output_w, output_h]\u001b[39;00m\n\u001b[1;32m     81\u001b[0m gaussians \u001b[38;5;241m=\u001b[39m intensity \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;241m-\u001b[39m(\n\u001b[0;32m---> 83\u001b[0m         \u001b[43m(\u001b[49m\u001b[43mX_diff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigma_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_diff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigma_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_diff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY_diff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigma_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m )  \u001b[38;5;66;03m# [batch, num_gaussians, output_w, output_h]\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Sum over all Gaussians\u001b[39;00m\n\u001b[1;32m     90\u001b[0m output \u001b[38;5;241m=\u001b[39m gaussians\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: [batch, output_w, output_h]\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.93 GiB. GPU "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from net.utils import get_model_memory_nolog\n",
    "# Define the MLP Gaussian Decoder\n",
    "class MLP_GaussianDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_gaussians, output_h, output_w):\n",
    "        super().__init__()\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.output_h = output_h\n",
    "        self.output_w = output_w\n",
    "        \n",
    "        # MLP to generate Gaussian parameters\n",
    "        self.mlp = nn.Sequential(\n",
    "        #     nn.Linear(input_dim, num_gaussians * 6 *2),  # Input -> hidden layer 0.72G\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(num_gaussians * 6 *2, num_gaussians * 6),       # Hidden -> hidden\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(num_gaussians * 6, num_gaussians * 6)  # Hidden -> Gaussian parameters\n",
    "        # )\n",
    "            nn.Linear(input_dim, 512),  # Input -> hidden layer 0.30G\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),       # Hidden -> hidden\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_gaussians * 6)  # Hidden -> Gaussian parameters\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z: Input encoded vector of shape [batch, length, channel]\n",
    "        Returns: Decoded Gaussian-based image of shape [batch, output_h, output_w]\n",
    "        \"\"\"\n",
    "        batch_size, length, channel = z.shape\n",
    "\n",
    "        # Flatten the input for MLP (combine length and channel dimensions)\n",
    "        z_flat = z.view(batch_size, -1)  # Shape: [batch, length * channel]\n",
    "\n",
    "        # Generate Gaussian parameters\n",
    "        params = self.mlp(z_flat)  # Shape: [batch, num_gaussians * 6]\n",
    "        params = params.view(batch_size, self.num_gaussians, 6)  # [batch, num_gaussians, 6]\n",
    "\n",
    "        # Separate Gaussian parameters: x, y, sigma_x, sigma_y, rho, intensity\n",
    "        xc, yc, sigma_x, sigma_y, rho, intensity = torch.chunk(params, 6, dim=-1)\n",
    "\n",
    "        # Normalize xc, yc to [-1, 1] (image coordinate range)\n",
    "        xc = torch.tanh(xc)\n",
    "        yc = torch.tanh(yc)\n",
    "\n",
    "        # Ensure sigma_x, sigma_y > 0 (use softplus activation)\n",
    "        sigma_x = F.softplus(sigma_x) + 1e-6\n",
    "        sigma_y = F.softplus(sigma_y) + 1e-6\n",
    "\n",
    "        # Ensure rho is within a valid range [-1, 1] (correlation coefficient)\n",
    "        rho = torch.tanh(rho)\n",
    "\n",
    "        # Intensity can be scaled to [0, 1] using sigmoid\n",
    "        intensity = torch.sigmoid(intensity)\n",
    "\n",
    "        # Create a 2D grid for the output image\n",
    "        x = torch.linspace(-1, 1, self.output_w, device=z.device)\n",
    "        y = torch.linspace(-1, 1, self.output_h, device=z.device)\n",
    "        X, Y = torch.meshgrid(x, y, indexing=\"ij\")  # X, Y shape: [output_w, output_h]\n",
    "\n",
    "        # Expand X, Y to support broadcasting across batches and gaussians\n",
    "        X = X.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, output_w, output_h]\n",
    "        Y = Y.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, output_w, output_h]\n",
    "\n",
    "        # Expand Gaussian parameters to match grid dimensions\n",
    "        xc = xc.unsqueeze(-1).unsqueeze(-1)  # [batch, num_gaussians, 1, 1]\n",
    "        yc = yc.unsqueeze(-1).unsqueeze(-1)\n",
    "        sigma_x = sigma_x.unsqueeze(-1).unsqueeze(-1)\n",
    "        sigma_y = sigma_y.unsqueeze(-1).unsqueeze(-1)\n",
    "        rho = rho.unsqueeze(-1).unsqueeze(-1)\n",
    "        intensity = intensity.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # Compute Gaussian function for all Gaussians in parallel\n",
    "        X_diff = X - xc  # [batch, num_gaussians, output_w, output_h]\n",
    "        Y_diff = Y - yc  # [batch, num_gaussians, output_w, output_h]\n",
    "\n",
    "        gaussians = intensity * torch.exp(\n",
    "            -(\n",
    "                (X_diff ** 2) / (2 * sigma_x ** 2)\n",
    "                + (Y_diff ** 2) / (2 * sigma_y ** 2)\n",
    "                + rho * (X_diff * Y_diff) / (sigma_x * sigma_y)\n",
    "            )\n",
    "        )  # [batch, num_gaussians, output_w, output_h]\n",
    "\n",
    "        # Sum over all Gaussians\n",
    "        output = gaussians.sum(dim=1)  # Shape: [batch, output_w, output_h]\n",
    "\n",
    "        return output\n",
    "    \n",
    "# Hyperparameters\n",
    "batch_size = 10\n",
    "length = 281\n",
    "channel = 576\n",
    "output_h = 360\n",
    "output_w = 720\n",
    "device=torch.device('cuda:0')\n",
    "# Input encoded vector (randomly generated)\n",
    "encoded = torch.randn(batch_size, length, channel).to(device)  # Shape: [10, 281, 576]\n",
    "\n",
    "# Range of num_gaussians to test\n",
    "num_gaussians_list = [10, 50, 100, 200, 250] #1000在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。 根本就用不了。。\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "for num_gaussians in num_gaussians_list:\n",
    "    # Initialize the decoder with current num_gaussians\n",
    "    decoder = MLP_GaussianDecoder(input_dim=length * channel, num_gaussians=num_gaussians, output_h=output_h, output_w=output_w).to(device)\n",
    "\n",
    "    # Measure model size\n",
    "    model_memory = get_model_memory_nolog(decoder)\n",
    "\n",
    "    # Measure forward pass time\n",
    "    start_time = time.time()\n",
    "    output = decoder(encoded)  # Forward pass\n",
    "    end_time = time.time()\n",
    "    forward_time = end_time - start_time\n",
    "\n",
    "    # Record results\n",
    "    results.append((num_gaussians, model_memory, forward_time))\n",
    "    print(f\"num_gaussians: {num_gaussians}, Model Memory: {model_memory:.2f} GB, Forward Time: {forward_time:.4f} s\")\n",
    "\n",
    "    del decoder, output  # Delete references to the model and output\n",
    "    torch.cuda.empty_cache()  # Clear cached memor\n",
    "\n",
    "# Print all results\n",
    "print(\"\\nResults Summary:\")\n",
    "for num_gaussians, model_memory, forward_time in results:\n",
    "    print(f\"num_gaussians: {num_gaussians}, Model Memory: {model_memory:.2f} GB, Forward Time: {forward_time:.4f} s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jxtnett",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
