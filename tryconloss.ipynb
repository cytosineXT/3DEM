{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Convert spherical coordinates to cartesian\n",
    "def spherical_to_cartesian(theta, phi, device=\"cpu\"):\n",
    "    return torch.tensor([torch.sin(phi) * torch.cos(theta),\n",
    "                         torch.sin(phi) * torch.sin(theta),\n",
    "                         torch.cos(phi)], device=device, dtype=torch.float32)\n",
    "\n",
    "# Calculate the projected area of a triangle for a given view vector\n",
    "def calculate_projected_area(normal, area, view_vector):\n",
    "    dot_product = torch.dot(normal, view_vector)\n",
    "    return area * torch.abs(dot_product)\n",
    "\n",
    "# Calculate angular similarity between two views\n",
    "def angular_similarity(mesh, view1, view2, weight_area=0.5, weight_normals=0.5, device=\"cpu\"):\n",
    "    view_vector1 = spherical_to_cartesian(view1[0], view1[1], device=device)\n",
    "    view_vector2 = spherical_to_cartesian(view2[0], view2[1], device=device)\n",
    "\n",
    "    normals = torch.tensor(mesh.face_normals, dtype=torch.float32, device=device)\n",
    "    areas = torch.tensor(mesh.area_faces, dtype=torch.float32, device=device)\n",
    "\n",
    "    area_view1 = 0.\n",
    "    area_view2 = 0.\n",
    "    for face_idx in range(len(mesh.faces)):\n",
    "        normal = normals[face_idx]\n",
    "        area = areas[face_idx]\n",
    "        projected_area1 = calculate_projected_area(normal, area, view_vector1)\n",
    "        projected_area2 = calculate_projected_area(normal, area, view_vector2)\n",
    "        if torch.dot(normal, view_vector1) < 0:\n",
    "            area_view1 += projected_area1\n",
    "        if torch.dot(normal, view_vector2) < 0:\n",
    "            area_view2 += projected_area2\n",
    "\n",
    "    projected_areas_difference = torch.abs(area_view1 - area_view2)\n",
    "    similarity = 1 / (1 + 10 * projected_areas_difference.item())\n",
    "    similarity = max(0, min(similarity, 1))\n",
    "    return similarity, 1 - similarity\n",
    "\n",
    "# Calculate frequency similarity (absolute difference)\n",
    "def frequency_similarity(freq1, freq2):\n",
    "    return torch.abs(freq1 - freq2)\n",
    "\n",
    "# Custom contrastive loss for angles and frequencies\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.1, obj_folder='planes/'):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.obj_folder = obj_folder\n",
    "\n",
    "    def load_mesh(self, plane_name):\n",
    "        # Get the first 4 characters of the plane name\n",
    "        plane_prefix = plane_name[:4]\n",
    "\n",
    "        # Find the .obj file that matches the plane_prefix in the folder\n",
    "        matching_files = glob.glob(os.path.join(self.obj_folder, f'{plane_prefix}*.obj'))\n",
    "        if len(matching_files) == 0:\n",
    "            raise FileNotFoundError(f\"No matching .obj file found for {plane_name}\")\n",
    "        \n",
    "        # Load the first matching file (assuming there's only one match)\n",
    "        obj_file = matching_files[0]\n",
    "        print(f\"Loading mesh for {plane_name} from {obj_file}\")\n",
    "        \n",
    "        # Load the mesh using trimesh\n",
    "        mesh = trimesh.load(obj_file)\n",
    "        return mesh\n",
    "\n",
    "    def forward(self, rcs, in_em,device, beta=0.1):\n",
    "        batch_size = rcs.shape[0]  # 6 in your case\n",
    "\n",
    "        # Split in_em into plane names, incident angles (2 values), and frequency (1 value)\n",
    "        plane_names = in_em[0]  # shape: (batch_size,)\n",
    "        angles = in_em[1:3]     # shape: (6, 2) - second and third columns are the incident angles\n",
    "        freqs = in_em[3]        # shape: (6,) - fourth column is the frequency\n",
    "\n",
    "        # Initialize the total loss and pair counter\n",
    "        total_loss = 0.0\n",
    "        pair_count = 0\n",
    "\n",
    "        # Loop over all pairs of RCS matrices in the batch\n",
    "        for i in range(batch_size):\n",
    "            # Load the mesh for the current plane name\n",
    "            mesh_i = self.load_mesh(plane_names[i])\n",
    "\n",
    "            for j in range(i + 1, batch_size):\n",
    "                # Only compare samples from the same plane\n",
    "                if plane_names[i] == plane_names[j]:\n",
    "                    # Extract the RCS matrices for the ith and jth samples\n",
    "                    rcs_i = rcs[i]  # shape: (360, 720)\n",
    "                    rcs_j = rcs[j]  # shape: (360, 720)\n",
    "\n",
    "                    # Compute the MSE loss between the two RCS matrices\n",
    "                    rcs_loss = F.mse_loss(rcs_i, rcs_j)\n",
    "\n",
    "                    # Load the mesh for the jth plane name\n",
    "                    mesh_j = self.load_mesh(plane_names[j])\n",
    "\n",
    "                    # Compute the angle similarity between the ith and jth samples\n",
    "                    view1 = (np.radians(angles[0][i]), np.radians(angles[1][i]))\n",
    "                    view2 = (np.radians(angles[0][j]), np.radians(angles[1][j]))\n",
    "                    \n",
    "                    # Use the mesh from the ith plane (since both planes are the same here)\n",
    "                    angle_sim, angle_dif = angular_similarity(mesh_i, view1, view2, weight_area=0.5, weight_normals=0., device=device)\n",
    "\n",
    "                    # Compute the frequency similarity between the ith and jth samples\n",
    "                    freq_sim, freq_dif = frequency_similarity(freqs[i], freqs[j])\n",
    "\n",
    "                    # Calculate angle and frequency losses\n",
    "                    angle_loss = rcs_loss * angle_sim - max(0, rcs_loss - self.margin) * angle_dif\n",
    "                    freq_loss = rcs_loss * freq_sim - max(0, rcs_loss - self.margin) * freq_dif\n",
    "\n",
    "                    # Combine the two losses\n",
    "                    pairwise_loss = angle_loss + beta * freq_loss\n",
    "\n",
    "                    # Accumulate the pairwise loss\n",
    "                    total_loss += pairwise_loss\n",
    "\n",
    "                    # Increment the pair counter since we found a matching pair\n",
    "                    pair_count += 1\n",
    "\n",
    "        # Return the total contrastive loss, averaged by the number of valid pairs\n",
    "        if pair_count > 0:\n",
    "            return total_loss / pair_count\n",
    "        else:\n",
    "            # If no pairs were found, return zero loss\n",
    "            return torch.tensor(0.0, device=rcs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mesh for b7fd from planes/b7fd11d4af74b4ffddaa0161e9d3dfac.obj\n",
      "Loading mesh for b7fd from planes/b7fd11d4af74b4ffddaa0161e9d3dfac.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70799/119674080.py:105: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  view1 = (np.radians(angles[0][i]), np.radians(angles[1][i]))\n",
      "/tmp/ipykernel_70799/119674080.py:106: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  view2 = (np.radians(angles[0][j]), np.radians(angles[1][j]))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m contrastive_loss_fn \u001b[38;5;241m=\u001b[39m ContrastiveLoss()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate contrastive loss\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcontrastive_loss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_em\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContrastive Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnet/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnet/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 112\u001b[0m, in \u001b[0;36mContrastiveLoss.forward\u001b[0;34m(self, rcs, in_em, device, beta)\u001b[0m\n\u001b[1;32m    109\u001b[0m angle_sim, angle_dif \u001b[38;5;241m=\u001b[39m angular_similarity(mesh_i, view1, view2, weight_area\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, weight_normals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Compute the frequency similarity between the ith and jth samples\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m freq_sim, freq_dif \u001b[38;5;241m=\u001b[39m frequency_similarity(freqs[i], freqs[j])\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Calculate angle and frequency losses\u001b[39;00m\n\u001b[1;32m    115\u001b[0m angle_loss \u001b[38;5;241m=\u001b[39m rcs_loss \u001b[38;5;241m*\u001b[39m angle_sim \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, rcs_loss \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin) \u001b[38;5;241m*\u001b[39m angle_dif\n",
      "File \u001b[0;32m~/anaconda3/envs/jxtnet/lib/python3.9/site-packages/torch/_tensor.py:1047\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m   1049\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1050\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1051\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1056\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "# Example usage in your training loop\n",
    "in_em = [('b7fd', 'bb7c', 'b7fd', 'bb7c'), \n",
    "         torch.tensor([30, 150, 150, 150]), \n",
    "         torch.tensor([270, 60, 150, 330]), \n",
    "         torch.tensor([0.9375, 0.8192, 0.8591, 0.9227], device='cuda:0')]\n",
    "\n",
    "decoded = torch.rand([4, 1, 360, 720], device='cuda:0')\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Instantiate the loss function\n",
    "contrastive_loss_fn = ContrastiveLoss()\n",
    "\n",
    "# Calculate contrastive loss\n",
    "loss = contrastive_loss_fn(decoded, in_em, device=device)\n",
    "print(\"Contrastive Loss:\", loss.item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jxtnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
